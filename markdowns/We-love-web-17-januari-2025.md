Op 9 december werkte ik aan de "Code/Design User Testing" voor mijn interactie. Ik gebruikte de user story die ik eerder had aangemaakt als basis om een testplan te schrijven. Vervolgens voerde ik de test uit met  drie gebruikers.  Na afloop deelde ik de resultaten en mijn bevindingen als een comment op het issue 'User Story'.

# The rise of AI-powered voice interface

Teckniek die al 7 jaar bestaat, het is een applicatie die helpt transciberen.
https://[presi-parrot](https://presi-parrot.davebitter.com/).davebitter.com/


A brief history in voice recognition
1990: programma's van grote bedrijven
2000: google kwam met een zoekfunctie waar je dingen kan inspreken
2010: het werd steeds normaal om tegen een apparaat te praten
2020: microsoft teams: transcripts die je kan generen. 

There is a change happening in how people find information
Chatting with AI is cool, but we can make is awesome. 


An AI assistent where you can talk to: https://aiva.davebitter.com/
Hij vertelt tegen de computer en wordt gestuurd naar een soort chatgpt API en dan krijg je een antwoord. Belangrijk is dat het programma je stem kan herkennen. 
- rate: snelheid
- pitch: hoogte


Connecting it with the AI (how do i provide context?)
- How the AI is being used
- The personality of the AI
- The select role by the user

And much requiered feedback to the user"
- animatie in vorm van een rondje die weinig beweegt
- Animatie dat meer beweegt als het luistert > feedback aan de gebruiker

When in doubt, more in AI
- ElevenLabs: gratis accounts die stemmen generen
- Eerste versie: niet handig want je het moest telkens naar elevenlabs om de tekst te sturen. De stem is ook best langzaam. 
- Fetch all audio data en dan play all audio data > zo deed hij het eerst. Daarna kwam hij op het idee om per tekst te werken. 

AI is just another data source. It's the UX that makes the difference.



